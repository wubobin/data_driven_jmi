{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb8e9005-1705-4329-86ba-3588fa312542",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core import Structure\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f799f-cbea-4599-871a-ab0da6c25694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对DFT直接拟合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a0e7a0b-0336-4e8f-ad4d-059ebbd4ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/home/jupyter/DFT/bandgap/bandgap_json/DFT_bandgapTrain1.json\", \"r\") as f:\n",
    "    data_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10b11eb8-0c2e-4908-8b59-b9ce22f3e87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = []\n",
    "DFT_bandgaps = []\n",
    "\n",
    "for item in data_train:\n",
    "    structure = Structure.from_dict(item['structure'])\n",
    "    gap = item['bandgap']\n",
    "    structures.append(structure)\n",
    "    DFT_bandgaps.append(gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afee02c-3f9f-420c-a6c8-2d02368e2cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5是最低截断半径，用以判断哪两个原子之间有键连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87e5753-3f9d-4f68-b64e-4a844fb591ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 09:52:21.396633: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-01 09:52:21.426402: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/opt/tefscloud/miniconda3/lib/python3.9/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 20s 20s/step - loss: 3.8083\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 3.7118\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 3.6088\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 3.4906\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 3.3498\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 3.1791\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 2.9695\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 2.7102\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 2.3878\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 1.9872\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 1.4970\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 1s 804ms/step - loss: 0.9276\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.3717\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.2127\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.9366\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.8459\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.4396\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 1s 789ms/step - loss: 0.2040\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.1768\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.2448\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 1s 807ms/step - loss: 0.3260\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.3846\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.4103\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.4042\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.3721\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.3225\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.2656\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.2135\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1782\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.1687\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1858\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 1s 800ms/step - loss: 0.2179\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.2443\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.2490\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 1s 809ms/step - loss: 0.2313\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.2035\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.1797\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1676\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1673\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 1s 784ms/step - loss: 0.1746\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1841\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1915\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.1946\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1925\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 1s 788ms/step - loss: 0.1863\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.1780\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1699\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1643\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1624\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 1s 814ms/step - loss: 0.1639\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 1s 797ms/step - loss: 0.1674\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1705\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1714\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1696\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.1658\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1617\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.1587\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1573\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1574\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1582\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1589\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1587\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1576\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1557\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1535\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1515\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1501\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1494\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 1s 785ms/step - loss: 0.1490\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 1s 801ms/step - loss: 0.1487\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1480\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1468\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.1453\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.1436\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.1422\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.1411\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1402\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1395\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1387\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.1378\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 1s 790ms/step - loss: 0.1367\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1355\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1345\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 1s 794ms/step - loss: 0.1337\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1331\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1327\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.1323\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 1s 792ms/step - loss: 0.1318\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.1313\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 1s 795ms/step - loss: 0.1309\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1305\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1303\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 1s 786ms/step - loss: 0.1301\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 1s 793ms/step - loss: 0.1300\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 1s 805ms/step - loss: 0.1298\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 1s 796ms/step - loss: 0.1296\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 1s 802ms/step - loss: 0.1293\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 1s 791ms/step - loss: 0.1290\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 1s 799ms/step - loss: 0.1287\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 1s 798ms/step - loss: 0.1285\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 设置参数列表\n",
    "nfeat_bond_list = [10, 15, 20, 25, 30]\n",
    "r_cutoff_list = [6, 7, 8, 9, 10]\n",
    "\n",
    "# 初始化结果记录\n",
    "results = []\n",
    "\n",
    "# 循环训练模型\n",
    "for nfeat_bond in nfeat_bond_list:\n",
    "    for r_cutoff in r_cutoff_list:\n",
    "        # 设置参数\n",
    "        gaussian_centers = np.linspace(0, r_cutoff+1, nfeat_bond)\n",
    "        gaussian_width = 0.5\n",
    "        graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "        \n",
    "        # 初始化模型\n",
    "        model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)\n",
    "        \n",
    "        # 训练模型\n",
    "        model.train(structures,DFT_bandgaps, epochs=100)\n",
    "        \n",
    "        # 预测结果\n",
    "        predictions = []\n",
    "        for structure in structures:\n",
    "            prediction = model.predict_structure(structure)\n",
    "            predictions.append(prediction[0])\n",
    "        \n",
    "        # 计算评估指标\n",
    "        mse = mean_squared_error(DFT_bandgaps, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(DFT_bandgaps, predictions)\n",
    "        r2 = r2_score(DFT_bandgaps, predictions)\n",
    "        \n",
    "        # 记录结果\n",
    "        results.append({\n",
    "            'nfeat_bond': nfeat_bond,\n",
    "            'r_cutoff': r_cutoff,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426c568e-cedc-4eab-ab50-d1890a4db69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印结果\n",
    "for result in results:\n",
    "    print(f\"nfeat_bond: {result['nfeat_bond']}, r_cutoff: {result['r_cutoff']}, MSE: {result['mse']}, RMSE: {result['rmse']}, MAE: {result['mae']}, R2: {result['r2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7700dbde-a19a-4bab-b651-eae683bd3538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_r2(results):\n",
    "    # 找到R2最大的结果\n",
    "    best_result = max(results, key=lambda result: result['r2'])\n",
    "    return best_result\n",
    "\n",
    "def get_best_rmse(results):\n",
    "    # 计算每个结果的RMSE\n",
    "    for result in results:\n",
    "        result['rmse'] = np.sqrt(result['mse'])\n",
    "    \n",
    "    # 找到RMSE最小的结果\n",
    "    best_result = min(results, key=lambda result: result['rmse'])\n",
    "    return best_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fd06bd5e-0bad-47e9-81ac-447374cd8229",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best R2: 0.9270888299996547, nfeat_bond: 10, r_cutoff: 8\n",
      "Best RMSE: 0.10564542482733762, nfeat_bond: 10, r_cutoff: 8\n"
     ]
    }
   ],
   "source": [
    "best_r2_result = get_best_r2(results)\n",
    "print(f\"Best R2: {best_r2_result['r2']}, nfeat_bond: {best_r2_result['nfeat_bond']}, r_cutoff: {best_r2_result['r_cutoff']}\")\n",
    "\n",
    "best_rmse_result = get_best_rmse(results)\n",
    "print(f\"Best RMSE: {best_rmse_result['rmse']}, nfeat_bond: {best_rmse_result['nfeat_bond']}, r_cutoff: {best_rmse_result['r_cutoff']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5947b60f-841f-4df8-a886-c1d4a3911c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086bb319-af56-46d8-824d-d5e5d07b29a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_mae(results):\n",
    "    # 计算每个结果的MAE\n",
    "    for result in results:\n",
    "        result['mae'] = mean_absolute_error(gaps, predictions)\n",
    "    \n",
    "    # 找到MAE最小的结果\n",
    "    best_result = min(results, key=lambda result: result['mae'])\n",
    "    return best_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "438f4b66-0c42-4ac0-9bac-2a679569d72b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best MAE: 0.07920198556232247, nfeat_bond: 10, r_cutoff: 6\n"
     ]
    }
   ],
   "source": [
    "best_mae_result = get_best_mae(results)\n",
    "print(f\"Best MAE: {best_mae_result['mae']}, nfeat_bond: {best_mae_result['nfeat_bond']}, r_cutoff: {best_mae_result['r_cutoff']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa66f49a-943a-41d1-aa0f-fdb357d0cb15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 26 22:41:46 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-32GB           On  | 00000000:00:08.0 Off |                    0 |\n",
      "| N/A   31C    P0              22W / 300W |      2MiB / 32768MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d27d940-7588-419c-8dab-bf4cc7351508",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 22s 22s/step - loss: 0.1537\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1537\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1532\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1529\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1528\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1527\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1524\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1521\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1519\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1517\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1512\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1507\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1502\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1495\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1486\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1474\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1460\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1440\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1418\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1387\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1353\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1312\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1282\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1290\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1294\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1267\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1235\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1194\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1173\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1142\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1113\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.1061\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0997\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0918\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0807\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0701\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0692\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0894\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0497\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0598\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0471\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0624\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0447\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0594\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0423\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0495\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0390\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0459\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0359\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0431\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0356\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0381\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0375\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0348\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0386\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0337\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0350\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0333\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0317\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0329\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0307\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0317\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0299\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0304\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0291\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0298\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0281\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0284\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0268\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0274\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0266\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0262\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0258\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0252\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0253\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0245\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0246\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0234\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0238\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0230\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0227\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0228\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0220\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0221\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0222\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0215\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0211\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0213\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0215\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0219\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0212\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0206\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0203\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0204\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0210\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0216\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0241\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0216\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0201\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 4s 4s/step - loss: 0.0197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tefscloud/miniconda3/lib/python3.9/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 26s 26s/step - loss: 0.1534\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1533\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1531\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1528\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1528\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1527\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1525\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1522\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1521\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1518\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1514\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1509\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1504\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1497\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1487\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1477\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1462\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1444\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1422\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1397\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1368\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1349\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1355\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1370\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1363\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1345\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1328\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1323\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1320\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1320\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1317\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1310\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1301\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1287\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1272\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1252\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1233\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1213\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1187\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1153\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1110\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1078\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1040\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0912\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0880\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0920\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0814\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0602\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0875\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.1639\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0664\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0993\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0963\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0722\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0836\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0965\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0931\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0830\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0801\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0862\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0906\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0856\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0784\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0781\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0815\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0790\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0704\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0665\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0685\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0629\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0549\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0581\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0525\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0535\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0546\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0597\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0527\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0567\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0481\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0515\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0483\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0501\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0507\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0492\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0509\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0494\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0486\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0488\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0464\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0471\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0456\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0466\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0459\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0468\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0456\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0461\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0448\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0451\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0442\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 7s 7s/step - loss: 0.0446\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "# 设置参数列表\n",
    "nfeat_bond_list2 = [10]\n",
    "r_cutoff_list2 = [10,12]#越高，计算时间越长，更多的边，键长信息将被处理\n",
    "\n",
    "# 初始化结果记录\n",
    "results2 = []\n",
    "\n",
    "# 循环训练模型\n",
    "for nfeat_bond in nfeat_bond_list2:\n",
    "    for r_cutoff in r_cutoff_list2:\n",
    "        # 设置参数\n",
    "        gaussian_centers = np.linspace(0, r_cutoff+1, nfeat_bond)\n",
    "        gaussian_width = 0.5\n",
    "        graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "        \n",
    "        # 初始化模型\n",
    "        model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)\n",
    "        \n",
    "        # 训练模型\n",
    "        model.train(structures, gaps, epochs=100)\n",
    "        \n",
    "        # 预测结果\n",
    "        predictions = []\n",
    "        for structure in structures:\n",
    "            prediction = model.predict_structure(structure)\n",
    "            predictions.append(prediction[0])\n",
    "        \n",
    "        # 计算评估指标\n",
    "        mse = mean_squared_error(gaps, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(gaps, predictions)\n",
    "        r2 = r2_score(gaps, predictions)\n",
    "        \n",
    "        # 记录结果\n",
    "        results2.append({\n",
    "            'nfeat_bond': nfeat_bond,\n",
    "            'r_cutoff': r_cutoff,\n",
    "            'mse': mse,\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffde07ba-6e92-447e-9204-634e832df8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nfeat_bond: 10, r_cutoff: 10, MSE: 0.020761438802568193, RMSE: 0.1440883021017605, MAE: 0.1092880264815893, R2: 0.8643717596519871\n",
      "nfeat_bond: 10, r_cutoff: 12, MSE: 0.0441800792883566, RMSE: 0.210190578495699, MAE: 0.1498537179177882, R2: 0.7113848192653066\n"
     ]
    }
   ],
   "source": [
    "# 打印结果\n",
    "for result in results2:\n",
    "    print(f\"nfeat_bond: {result['nfeat_bond']}, r_cutoff: {result['r_cutoff']}, MSE: {result['mse']}, RMSE: {result['rmse']}, MAE: {result['mae']}, R2: {result['r2']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb02e6-47db-402e-aad5-2ea386fd2c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
