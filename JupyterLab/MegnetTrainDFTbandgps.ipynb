{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "261ce5eb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 14:20:24.771174: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-11-27 14:20:24.774541: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 14:20:24.817752: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-27 14:20:24.817790: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-27 14:20:24.817818: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-27 14:20:24.825757: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-27 14:20:24.826707: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-27 14:20:25.665843: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core import Structure\n",
    "from megnet.models import MEGNetModel\n",
    "from megnet.data.crystal import CrystalGraph\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c668f8-52ca-4050-b3b0-9aad1b1ee5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/root/public/bandgap_json/DFT_bandgaptrain1.json\", \"r\") as f:\n",
    "    data_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c4c4edf-b511-475d-b898-d755030861a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures = []\n",
    "DFT_gaps = []\n",
    "\n",
    "for item in data_train:\n",
    "    structure = Structure.from_dict(item['structure'])\n",
    "    gap = item['bandgap']\n",
    "    structures.append(structure)\n",
    "    DFT_gaps.append(gap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40dcbc2b-8617-410c-b849-16e527783e12",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Structure Summary\n",
       "Lattice\n",
       "    abc : 18.529572012331908 6.521252982657742 6.245166844454914\n",
       " angles : 89.99999038110161 89.99998025920198 90.000004174406\n",
       " volume : 754.6411478921391\n",
       "      A : 18.529572012330846 1.24694756e-08 6.2709044361e-06\n",
       "      B : -4.795086209e-07 6.521252982657631 1.1054893964e-06\n",
       "      C : 3.81897325e-08 -1.02393447e-08 6.245166844454914\n",
       "    pbc : True True True\n",
       "PeriodicSite: H (4.345, 3.261, 3.123) [0.2345, 0.5, 0.5]\n",
       "PeriodicSite: H (10.52, 3.261, 3.123) [0.5678, 0.5, 0.5]\n",
       "PeriodicSite: H (16.7, 3.261, 3.123) [0.9012, 0.5, 0.5]\n",
       "PeriodicSite: H (3.257, 3.261, 1.132) [0.1758, 0.5, 0.1812]\n",
       "PeriodicSite: H (9.433, 3.261, 1.132) [0.5091, 0.5, 0.1812]\n",
       "PeriodicSite: H (15.61, 3.261, 1.132) [0.8424, 0.5, 0.1812]\n",
       "PeriodicSite: H (1.646, 3.261, 1.823) [0.08884, 0.5, 0.2919]\n",
       "PeriodicSite: H (7.823, 3.261, 1.823) [0.4222, 0.5, 0.2919]\n",
       "PeriodicSite: H (14.0, 3.261, 1.823) [0.7555, 0.5, 0.2919]\n",
       "PeriodicSite: H (1.646, 3.261, 4.422) [0.08884, 0.5, 0.7081]\n",
       "PeriodicSite: H (7.823, 3.261, 4.422) [0.4222, 0.5, 0.7081]\n",
       "PeriodicSite: H (14.0, 3.261, 4.422) [0.7555, 0.5, 0.7081]\n",
       "PeriodicSite: H (3.257, 3.261, 5.114) [0.1758, 0.5, 0.8188]\n",
       "PeriodicSite: H (9.433, 3.261, 5.114) [0.5091, 0.5, 0.8188]\n",
       "PeriodicSite: H (15.61, 3.261, 5.114) [0.8424, 0.5, 0.8188]\n",
       "PeriodicSite: Pb (6.005, 4.047e-09, 2.157e-06) [0.3241, 9.71e-13, 2.002e-08]\n",
       "PeriodicSite: Pb (12.18, 8.204e-09, 4.248e-06) [0.6574, 9.71e-13, 2.002e-08]\n",
       "PeriodicSite: Pb (18.36, 1.236e-08, 6.275e-06) [0.9907, 9.71e-13, 1.002e-08]\n",
       "PeriodicSite: C (3.253, 3.261, 3.123) [0.1756, 0.5, 0.5]\n",
       "PeriodicSite: C (9.43, 3.261, 3.123) [0.5089, 0.5, 0.5]\n",
       "PeriodicSite: C (15.61, 3.261, 3.123) [0.8422, 0.5, 0.5]\n",
       "PeriodicSite: I (5.719, 3.261, 4.424e-06) [0.3086, 0.5, 3.1e-07]\n",
       "PeriodicSite: I (11.9, 3.261, 6.514e-06) [0.642, 0.5, 3.1e-07]\n",
       "PeriodicSite: I (18.07, 3.261, 8.605e-06) [0.9753, 0.5, 3.1e-07]\n",
       "PeriodicSite: Br (5.921, -1.142e-09, 3.123) [0.3195, -1.024e-12, 0.5]\n",
       "PeriodicSite: Br (12.1, 3.014e-09, 3.123) [0.6529, -1.024e-12, 0.5]\n",
       "PeriodicSite: Br (18.27, 7.171e-09, 3.123) [0.9862, -1.024e-12, 0.5]\n",
       "PeriodicSite: Br (2.676, 1.796e-09, 1.78e-06) [0.1444, -8.045e-13, 1.4e-07]\n",
       "PeriodicSite: Br (8.853, 5.952e-09, 3.87e-06) [0.4778, -8.045e-13, 1.4e-07]\n",
       "PeriodicSite: Br (15.03, 1.011e-08, 5.898e-06) [0.8111, -8.045e-13, 1.3e-07]\n",
       "PeriodicSite: N (2.658, 3.261, 1.956) [0.1435, 0.5, 0.3132]\n",
       "PeriodicSite: N (8.835, 3.261, 1.956) [0.4768, 0.5, 0.3132]\n",
       "PeriodicSite: N (15.01, 3.261, 1.956) [0.8101, 0.5, 0.3132]\n",
       "PeriodicSite: N (2.658, 3.261, 4.289) [0.1435, 0.5, 0.6868]\n",
       "PeriodicSite: N (8.835, 3.261, 4.289) [0.4768, 0.5, 0.6868]\n",
       "PeriodicSite: N (15.01, 3.261, 4.289) [0.8101, 0.5, 0.6868]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "structures[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ae03b84-59a8-4442-b1b3-25a7fbc77902",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-27 14:22:05.426357: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-11-27 14:22:05.457495: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "/opt/tefscloud/miniconda3/lib/python3.9/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "nfeat_bond = 10\n",
    "r_cutoff = 8\n",
    "gaussian_centers = np.linspace(0, r_cutoff+1, nfeat_bond)\n",
    "gaussian_width = 0.5\n",
    "graph_converter = CrystalGraph(cutoff=r_cutoff)\n",
    "model = MEGNetModel(graph_converter=graph_converter, centers=gaussian_centers, width=gaussian_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9975d036-bd73-46c6-922e-1567881b35d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1/1 [==============================] - 22s 22s/step - loss: 3.7811\n",
      "Epoch 2/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.6583\n",
      "Epoch 3/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.5205\n",
      "Epoch 4/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.3559\n",
      "Epoch 5/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 3.1568\n",
      "Epoch 6/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.9152\n",
      "Epoch 7/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.6218\n",
      "Epoch 8/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 2.2670\n",
      "Epoch 9/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.8424\n",
      "Epoch 10/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 1.3481\n",
      "Epoch 11/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8095\n",
      "Epoch 12/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3275\n",
      "Epoch 13/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2197\n",
      "Epoch 14/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8133\n",
      "Epoch 15/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.8321\n",
      "Epoch 16/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.5094\n",
      "Epoch 17/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2584\n",
      "Epoch 18/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1773\n",
      "Epoch 19/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2030\n",
      "Epoch 20/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2652\n",
      "Epoch 21/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3235\n",
      "Epoch 22/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3612\n",
      "Epoch 23/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3738\n",
      "Epoch 24/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3634\n",
      "Epoch 25/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.3349\n",
      "Epoch 26/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2948\n",
      "Epoch 27/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2509\n",
      "Epoch 28/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2114\n",
      "Epoch 29/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1841\n",
      "Epoch 30/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1742\n",
      "Epoch 31/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1825\n",
      "Epoch 32/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2029\n",
      "Epoch 33/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2243\n",
      "Epoch 34/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2356\n",
      "Epoch 35/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2319\n",
      "Epoch 36/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.2165\n",
      "Epoch 37/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1974\n",
      "Epoch 38/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1819\n",
      "Epoch 39/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1738\n",
      "Epoch 40/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1731\n",
      "Epoch 41/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1774\n",
      "Epoch 42/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1837\n",
      "Epoch 43/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1892\n",
      "Epoch 44/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1923\n",
      "Epoch 45/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1921\n",
      "Epoch 46/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1890\n",
      "Epoch 47/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1840\n",
      "Epoch 48/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1784\n",
      "Epoch 49/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1737\n",
      "Epoch 50/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1709\n",
      "Epoch 51/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1704\n",
      "Epoch 52/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1717\n",
      "Epoch 53/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1739\n",
      "Epoch 54/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1758\n",
      "Epoch 55/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1764\n",
      "Epoch 56/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1754\n",
      "Epoch 57/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1733\n",
      "Epoch 58/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1709\n",
      "Epoch 59/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1688\n",
      "Epoch 60/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1677\n",
      "Epoch 61/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1674\n",
      "Epoch 62/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1677\n",
      "Epoch 63/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1682\n",
      "Epoch 64/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1685\n",
      "Epoch 65/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1683\n",
      "Epoch 66/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1675\n",
      "Epoch 67/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1664\n",
      "Epoch 68/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1652\n",
      "Epoch 69/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1640\n",
      "Epoch 70/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1632\n",
      "Epoch 71/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1627\n",
      "Epoch 72/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1624\n",
      "Epoch 73/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1621\n",
      "Epoch 74/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1617\n",
      "Epoch 75/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1610\n",
      "Epoch 76/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1601\n",
      "Epoch 77/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1590\n",
      "Epoch 78/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1579\n",
      "Epoch 79/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1569\n",
      "Epoch 80/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1560\n",
      "Epoch 81/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1552\n",
      "Epoch 82/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1543\n",
      "Epoch 83/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1534\n",
      "Epoch 84/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1523\n",
      "Epoch 85/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1511\n",
      "Epoch 86/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1498\n",
      "Epoch 87/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1485\n",
      "Epoch 88/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1471\n",
      "Epoch 89/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1458\n",
      "Epoch 90/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1446\n",
      "Epoch 91/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1433\n",
      "Epoch 92/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1419\n",
      "Epoch 93/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1405\n",
      "Epoch 94/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1390\n",
      "Epoch 95/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1376\n",
      "Epoch 96/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1362\n",
      "Epoch 97/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1348\n",
      "Epoch 98/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1336\n",
      "Epoch 99/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1325\n",
      "Epoch 100/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1314\n",
      "Epoch 101/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1305\n",
      "Epoch 102/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1297\n",
      "Epoch 103/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1291\n",
      "Epoch 104/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1286\n",
      "Epoch 105/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1283\n",
      "Epoch 106/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1282\n",
      "Epoch 107/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1281\n",
      "Epoch 108/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1282\n",
      "Epoch 109/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1282\n",
      "Epoch 110/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1283\n",
      "Epoch 111/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1283\n",
      "Epoch 112/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1282\n",
      "Epoch 113/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1281\n",
      "Epoch 114/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1279\n",
      "Epoch 115/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1277\n",
      "Epoch 116/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1274\n",
      "Epoch 117/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1271\n",
      "Epoch 118/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1267\n",
      "Epoch 119/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1264\n",
      "Epoch 120/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1262\n",
      "Epoch 121/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1259\n",
      "Epoch 122/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1257\n",
      "Epoch 123/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1255\n",
      "Epoch 124/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1253\n",
      "Epoch 125/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1252\n",
      "Epoch 126/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1251\n",
      "Epoch 127/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1250\n",
      "Epoch 128/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1249\n",
      "Epoch 129/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1248\n",
      "Epoch 130/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1247\n",
      "Epoch 131/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1246\n",
      "Epoch 132/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1245\n",
      "Epoch 133/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1244\n",
      "Epoch 134/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1242\n",
      "Epoch 135/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1241\n",
      "Epoch 136/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1240\n",
      "Epoch 137/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1239\n",
      "Epoch 138/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1237\n",
      "Epoch 139/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1236\n",
      "Epoch 140/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1235\n",
      "Epoch 141/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1233\n",
      "Epoch 142/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1232\n",
      "Epoch 143/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1231\n",
      "Epoch 144/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1230\n",
      "Epoch 145/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1228\n",
      "Epoch 146/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1227\n",
      "Epoch 147/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1226\n",
      "Epoch 148/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1225\n",
      "Epoch 149/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1223\n",
      "Epoch 150/150\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.1222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<megnet.models.megnet.MEGNetModel at 0x7ff2afdc56d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model training\n",
    "# Here, `structures` is a list of pymatgen Structure objects.\n",
    "# `targets` is a corresponding list of properties.\n",
    "model.train(structures, DFT_gaps, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42cc1fd-4aa9-4668-a4b0-1c31e5bd454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用模型预测能带差\n",
    "predictions = []\n",
    "for structure in structures:\n",
    "    prediction = model.predict_structure(structure)\n",
    "    predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b21a6d-a341-4482-98c0-526a039f1ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算均方根误差、平均绝对误差和R²,# 计算MAE\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score  \n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(DFT_gaps, predictions))\n",
    "mae = mean_absolute_error(DFT_gaps, predictions)\n",
    "r2 = r2_score(DFT_gaps, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e440389e-2aa5-4dc2-801b-8e0cb4e8ffb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.30509469513611487\n",
      "0.2608312355135002\n",
      "0.3494036201347057\n"
     ]
    }
   ],
   "source": [
    "print(r2)\n",
    "print(mae)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "467b0e06-193e-46aa-afc4-6a6e7f12109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#模型无法直接预测带隙值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17fd39-5169-4e74-8d1e-cfe11dd3b788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae50f488-f89d-4d64-a1ed-1afb6a363267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
